{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1 - Used Cars in the USA\n",
    "#### By: David Wei, Sophia Wu, Dhruba Dey, Queena Wang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary:\n",
    "asdfasdfasdf\n",
    "\n",
    "#### Description:\n",
    "asdfasdfas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pip install missingno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#importing libraries and reading in file\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import missingno as msno\n",
    "warnings.filterwarnings('ignore') #ignoring warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# NOTE: need to change file per user\n",
    "#df_raw = pd.read_csv(r'C:\\Data\\used_cars_data.csv')\n",
    "df_raw = pd.read_csv('https://raw.githubusercontent.com/chee154/ml-Py-used_cars/main/data/kaggle_used_cars_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_raw.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Total # of Records: \" + str(df_raw.shape[0]))\n",
    "print(\"Total # of Columns: \" + str(df_raw.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reducing Dataset Attributes\n",
    "The total dataset has about 66 total columns. After a quick observation of the column headers, we can deduce that not all columns will be necessary for our analysis. Reasons for removing them below:\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#subsetting columns by referencing the column indexes\n",
    "df_cln_1 = df_raw.iloc[:, np.r_[0,5,7:11,13:17,18:21,22:30,32,35:38,42:50,51,55:57,61:63,64:66]]\n",
    "print(df_cln_1.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.matrix(df_cln_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing city_fuel_economy since a quick vizualition of our dataset shows that ALL values are empty\n",
    "df_cln_2 = df_cln_1.drop(columns='combine_fuel_economy')\n",
    "print(df_cln_2.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Cleaning - Datatypes\n",
    "Obviously at this point we need to convert a few of our data columns to the appropriate data type by removing parts of the value string that we do not need such as \"gal\" in the ful_tank_volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#finding all unique values per column to see what values we need to clean\n",
    "columns_that_need_cleaning = ['engine_type','exterior_color','frame_damaged','franchise_dealer','franchise_make','fuel_tank_volume','fuel_type','has_accidents','height','interior_color','isCab','is_new','length','listed_date','listing_color','make_name','maximum_seating','model_name','power','salvage','torque','transmission','wheel_system','wheel_system_display','width']\n",
    "for col in columns_that_need_cleaning:\n",
    "        print(df_cln_2[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#observing if 'engine_cylinders','engine_type' is the same data\n",
    "if df_cln_2['engine_cylinders'].equals(df_cln_2['engine_type']) == True:\n",
    "    df_cln_2 = df_cln_2.drop(columns='engine_cylinders')\n",
    "    print(df_cln_2.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After doing a quick profiling on some our identified columsn, we can see that both engine_cylinders and engine_type are the same. Additionally, we also found that the prefixes and suffixes attached to them are descriptive of it and thus not a continuous value. \n",
    "\n",
    "Regarding fuel_tank_volume and maximum_seating, we can see that there appears to be a pattern in the suffixes, \"gal\" and \"seats\" accordingly. We will now remove them and then convert all values to numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding all unique values per column to see what values we need to clean\n",
    "columns_that_need_cleaning_2 = ['fuel_tank_volume','height','length','maximum_seating','width',]\n",
    "for col in columns_that_need_cleaning_2:\n",
    "        print(df_cln_2[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#removing unecesary string values in columns\n",
    "#then cleaning up any values that contain '--' and replacing it with NaN\n",
    "#Lastly, converting the value first to a string type and then to a float type\n",
    "\n",
    "df_cln_2['fuel_tank_volume']=df_cln_2['fuel_tank_volume'].astype(str).str.replace(' gal', '').replace('--',np.NaN).astype(float)\n",
    "df_cln_2['height']=df_cln_2['height'].astype(str).str.replace(' in', '').replace('--',np.NaN).astype(float)\n",
    "df_cln_2['length']=df_cln_2['height'].astype(str).str.replace(' in', '').replace('--',np.NaN).astype(float)\n",
    "df_cln_2['maximum_seating']=df_cln_2['maximum_seating'].astype(str).str.replace(' seats', '').replace('--',np.NaN).astype(float)\n",
    "df_cln_2['width']=df_cln_1['width'].astype(str).str.replace(' in', '').replace('--',np.NaN).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "#fixing date type values from object type to date time\n",
    "df_cln_2['listed_date']=pd.to_datetime(df_cln_2['listed_date'])\n",
    "print(df_cln_2['listed_date'].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30000 entries, 0 to 29999\n",
      "Data columns (total 38 columns):\n",
      " #   Column                Non-Null Count  Dtype         \n",
      "---  ------                --------------  -----         \n",
      " 0   vin                   30000 non-null  object        \n",
      " 1   body_type             29851 non-null  object        \n",
      " 2   city                  30000 non-null  object        \n",
      " 3   city_fuel_economy     25067 non-null  float64       \n",
      " 4   daysonmarket          30000 non-null  int64         \n",
      " 5   engine_displacement   28227 non-null  float64       \n",
      " 6   engine_type           28994 non-null  object        \n",
      " 7   exterior_color        30000 non-null  object        \n",
      " 8   frame_damaged         15820 non-null  object        \n",
      " 9   franchise_dealer      30000 non-null  bool          \n",
      " 10  franchise_make        24272 non-null  object        \n",
      " 11  fuel_tank_volume      28339 non-null  float64       \n",
      " 12  fuel_type             29156 non-null  object        \n",
      " 13  has_accidents         15820 non-null  object        \n",
      " 14  height                28359 non-null  float64       \n",
      " 15  highway_fuel_economy  25067 non-null  float64       \n",
      " 16  horsepower            28227 non-null  float64       \n",
      " 17  interior_color        29998 non-null  object        \n",
      " 18  isCab                 15820 non-null  object        \n",
      " 19  is_new                30000 non-null  bool          \n",
      " 20  length                28359 non-null  float64       \n",
      " 21  listed_date           30000 non-null  datetime64[ns]\n",
      " 22  listing_color         30000 non-null  object        \n",
      " 23  make_name             30000 non-null  object        \n",
      " 24  maximum_seating       28359 non-null  float64       \n",
      " 25  mileage               28628 non-null  float64       \n",
      " 26  model_name            30000 non-null  object        \n",
      " 27  owner_count           14900 non-null  float64       \n",
      " 28  power                 25198 non-null  object        \n",
      " 29  price                 30000 non-null  float64       \n",
      " 30  salvage               15820 non-null  object        \n",
      " 31  seller_rating         29599 non-null  float64       \n",
      " 32  torque                24855 non-null  object        \n",
      " 33  transmission          29363 non-null  object        \n",
      " 34  wheel_system          28476 non-null  object        \n",
      " 35  wheel_system_display  28476 non-null  object        \n",
      " 36  width                 28359 non-null  float64       \n",
      " 37  year                  30000 non-null  int64         \n",
      "dtypes: bool(2), datetime64[ns](1), float64(13), int64(2), object(20)\n",
      "memory usage: 8.3+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#doing a quick profile on the subsetted columns\n",
    "print(df_cln_2.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now see that all of our column values have been adjusted to the correct datatypes. We will next proceed with cleaning up the values of our data. Since pandas default all 'object' types as strings, we will not need to convert these attribute types and can leave them as is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Cleaning - Data Values & NULLs\n",
    "Obviously at this point we need to convert a few of our data columns to the appropriate data type by removing parts of the value string that we do not need such as \"gal\" in the ful_tank_volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# finding all columns that have null values\n",
    "for i in df_cln_1.columns:\n",
    "    df_cln_1[i].isnull().any()\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#visualizing the \n",
    "msno.matrix(df_cln_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
