{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1 - Used Cars in the USA\n",
    "#### By: David Wei, Sophia Wu, Dhruba Dey, Queena Wang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary:\n",
    "asdfasdfasdf\n",
    "\n",
    "#### Description:\n",
    "asdfasdfas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install missingno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#importing libraries and reading in file\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import missingno as msno\n",
    "warnings.filterwarnings('ignore') #ignoring warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# NOTE: need to change file per user\n",
    "df_raw = pd.read_csv(r'C:\\Data\\used_cars_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_full.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total # of Records: \" + str(df_raw_full.shape[0]))\n",
    "print(\"Total # of Columns: \" + str(df_raw_full.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.matrix(df_cln_1)\n",
    "msno.heatmap(df_cln_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Total # of Records: \" + str(df_raw.shape[0]))\n",
    "print(\"Total # of Columns: \" + str(df_raw.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reducing Dataset Attributes\n",
    "The total dataset has about 66 total columns. After a quick observation of the column headers, we can deduce that not all columns will be necessary for our analysis. Reasons for removing them below:\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#subsetting columns by referencing the column indexes\n",
    "df_cln_1 = df_raw_full.iloc[:, np.r_[0,5,8:11,13:17,18:21,22:30,32,35:38,42:50,51,55:57,61:63,64:66]]\n",
    "print(\"final # of columns: \"+str(df_cln_1.shape[1]))\n",
    "\n",
    "\n",
    "print(df_cln_1.shape[1])\n",
    "print(df_cln_1.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#doing a quick profile on the subsetted columns\n",
    "print(df_cln_1.dtypes)\n",
    "print(\"------------------------------------------------\")\n",
    "print(df_cln_1.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Cleaning - Datatypes\n",
    "Obviously at this point we need to convert a few of our data columns to the appropriate data type by removing parts of the value string that we do not need such as \"gal\" in the ful_tank_volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#profiling class types:\n",
    "for col in ['engine_cylinders', 'engine_type','fuel_tank_volume','maximum_seating']:\n",
    "        print(df_cln_1[col].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After doing a quick profiling on some our identified columsn, we can see that both engine_cylinders and engine_type are the same. Additionally, we also found that the prefixes and suffixes attached to them are descriptive of it and thus not a continuous value. \n",
    "\n",
    "Regarding fuel_tank_volume and maximum_seating, we can see that there appears to be a pattern in the suffixes, \"gal\" and \"seats\" accordingly. We will now remove them and then convert all values to numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#removing unecesary string values in columns\n",
    "#then cleaning up any values that contain '--' and replacing it with NaN\n",
    "#Lastly, converting the value first to a string type and then to a float type\n",
    "\n",
    "df_cln_1['fuel_tank_volume']=df_cln_1['fuel_tank_volume'].str.replace(' gal', '').replace('--',np.NaN).astype(str).astype(float)\n",
    "df_cln_1['maximum_seating']=df_cln_1['maximum_seating'].str.replace(' seats', '').replace('--',np.NaN).astype(str).astype(float)\n",
    "df_cln_1['maximum_seating']=df_cln_1['maximum_seating'].str.replace(' seats', '').replace('--',np.NaN).astype(str).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#fixing date type values from object type to date time\n",
    "print(\"before date fix: \"+str(df_cln_1['listed_date'].head(2)))\n",
    "\n",
    "df_cln_1['listed_date']=pd.to_datetime(df_cln_1['listed_date'])\n",
    "print(df_cln_1['listed_date'].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#doing a quick profile on the subsetted columns\n",
    "print(df_cln_1.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_cln_1['franchise_dealer'].unique())\n",
    "print(df_cln_1['daysonmarket'].describe())\n",
    "print(np.var(df_cln_1['daysonmarket']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['agg.path.chunksize'] = 10000\n",
    "df = pd.DataFrame(df_cln_1,columns=['daysonmarket','price'])\n",
    "df.plot(x ='daysonmarket', y='price', kind = 'line')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now see that all of our column values have been adjusted to the correct datatypes. We will next proceed with cleaning up the values of our data. Since pandas default all 'object' types as strings, we will not need to convert these attribute types and can leave them as is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Cleaning - Data Values & NULLs\n",
    "Obviously at this point we need to convert a few of our data columns to the appropriate data type by removing parts of the value string that we do not need such as \"gal\" in the ful_tank_volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# finding all columns that have null values\n",
    "for i in df_cln_1.columns:\n",
    "    df_cln_1[i].isnull().any()\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#visualizing the \n",
    "msno.matrix(df_cln_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
