{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1 - Used Cars in the USA\n",
    "#### By: David Wei, Sophia Wu, Dhruba Dey, Queena Wang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary:\n",
    "asdfasdfasdf\n",
    "\n",
    "#### Description:\n",
    "asdfasdfas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#importing libraries and reading in file\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') #ignoring warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#import datafile from github repo\n",
    "df_raw = pd.read_csv('https://raw.githubusercontent.com/chee154/ml-Py-used_cars/main/data/kaggle_used_cars_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total # of Records: 30000\n",
      "Total # of Columns: 66\n"
     ]
    }
   ],
   "source": [
    "print(\"Total # of Records: \" + str(df_raw.shape[0]))\n",
    "print(\"Total # of Columns: \" + str(df_raw.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reducing Dataset Attributes\n",
    "The total dataset has about 66 total columns. After a quick observation of the column headers, we can deduce that not all columns will be necessary for our analysis. Reasons for removing them below:\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final # of columns: 21\n"
     ]
    }
   ],
   "source": [
    "#subsetting columns by referencing the column indexes\n",
    "df_cln_1 = df_raw.iloc[:, np.r_[5:8, 10, 13:16, 22:24, 26:27, 36:37, 42:49, 55:57, 65]]\n",
    "print(\"final # of columns: \"+str(df_cln_1.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "body_type                object\n",
      "cabin                    object\n",
      "city                     object\n",
      "daysonmarket              int64\n",
      "engine_cylinders         object\n",
      "engine_displacement     float64\n",
      "engine_type              object\n",
      "fuel_tank_volume         object\n",
      "fuel_type                object\n",
      "highway_fuel_economy    float64\n",
      "listed_date              object\n",
      "make_name                object\n",
      "maximum_seating          object\n",
      "mileage                 float64\n",
      "model_name               object\n",
      "owner_count             float64\n",
      "power                    object\n",
      "price                   float64\n",
      "torque                   object\n",
      "transmission             object\n",
      "year                      int64\n",
      "dtype: object\n",
      "------------------------------------------------\n",
      "       daysonmarket  engine_displacement  highway_fuel_economy        mileage  \\\n",
      "count  30000.000000         28227.000000          25067.000000   28628.000000   \n",
      "mean      75.603600          2972.352712             29.466310   31169.266487   \n",
      "std      108.743797          1349.350837              7.826778   45224.927636   \n",
      "min        0.000000           700.000000             12.000000       0.000000   \n",
      "25%       14.000000          2000.000000             25.000000       6.000000   \n",
      "50%       36.000000          2500.000000             29.000000    8598.500000   \n",
      "75%       80.000000          3600.000000             33.000000   43846.000000   \n",
      "max     2227.000000          8100.000000            127.000000  369016.000000   \n",
      "\n",
      "        owner_count          price          year  \n",
      "count  14900.000000   30000.000000  30000.000000  \n",
      "mean       1.537047   29854.286763   2017.675100  \n",
      "std        0.920585   18620.579826      4.303064  \n",
      "min        1.000000     484.000000   1941.000000  \n",
      "25%        1.000000   18289.500000   2017.000000  \n",
      "50%        1.000000   26366.500000   2020.000000  \n",
      "75%        2.000000   37985.000000   2020.000000  \n",
      "max       12.000000  432925.000000   2021.000000  \n"
     ]
    }
   ],
   "source": [
    "#doing a quick profile on the subsetted columns\n",
    "print(df_cln_1.dtypes)\n",
    "print(\"------------------------------------------------\")\n",
    "print(df_cln_1.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Cleaning - Datatypes\n",
    "Obviously at this point we need to convert a few of our data columns to the appropriate data type by removing parts of the value string that we do not need such as \"gal\" in the ful_tank_volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['V6' 'I4' nan 'V8' 'H4' 'H6' 'I6' 'V6 Flex Fuel Vehicle'\n",
      " 'V8 Flex Fuel Vehicle' 'I3' 'I6 Diesel' 'V6 Diesel' 'I4 Hybrid' 'V10'\n",
      " 'I5' 'I2' 'I4 Diesel' 'V8 Biodiesel' 'V8 Diesel' 'I4 Flex Fuel Vehicle'\n",
      " 'V6 Biodiesel' 'V12' 'V6 Hybrid' 'V8 Hybrid' 'W12' 'H4 Hybrid'\n",
      " 'I5 Diesel']\n",
      "['V6' 'I4' nan 'V8' 'H4' 'H6' 'I6' 'V6 Flex Fuel Vehicle'\n",
      " 'V8 Flex Fuel Vehicle' 'I3' 'I6 Diesel' 'V6 Diesel' 'I4 Hybrid' 'V10'\n",
      " 'I5' 'I2' 'I4 Diesel' 'V8 Biodiesel' 'V8 Diesel' 'I4 Flex Fuel Vehicle'\n",
      " 'V6 Biodiesel' 'V12' 'V6 Hybrid' 'V8 Hybrid' 'W12' 'H4 Hybrid'\n",
      " 'I5 Diesel']\n",
      "['26 gal' '10.8 gal' '21 gal' nan '19 gal' '19.3 gal' '13.5 gal'\n",
      " '12.7 gal' '--' '18 gal' '15.3 gal' '18.5 gal' '19.4 gal' '14.2 gal'\n",
      " '13.2 gal' '24 gal' '28 gal' '15.1 gal' '16.2 gal' '22.5 gal' '16.4 gal'\n",
      " '14 gal' '15.8 gal' '12.4 gal' '15.9 gal' '18.8 gal' '27.8 gal'\n",
      " '19.5 gal' '15.6 gal' '15.5 gal' '14.5 gal' '19.2 gal' '18.6 gal'\n",
      " '8.9 gal' '48 gal' '16.6 gal' '22.4 gal' '17.4 gal' '24.6 gal' '21.1 gal'\n",
      " '14.7 gal' '20.1 gal' '35 gal' '32 gal' '11.9 gal' '22 gal' '17.1 gal'\n",
      " '14.8 gal' '23 gal' '14.9 gal' '23.3 gal' '21.9 gal' '17.3 gal'\n",
      " '26.4 gal' '13.7 gal' '14.4 gal' '12.8 gal' '16 gal' '2.4 gal' '7 gal'\n",
      " '14.6 gal' '17.5 gal' '18.1 gal' '20 gal' '16.9 gal' '17.9 gal'\n",
      " '23.6 gal' '23.7 gal' '10.6 gal' '13 gal' '15.7 gal' '11.4 gal' '9 gal'\n",
      " '14.3 gal' '17 gal' '36 gal' '28.3 gal' '31 gal' '34 gal' '21.7 gal'\n",
      " '20.6 gal' '16.5 gal' '18.3 gal' '15.4 gal' '12.2 gal' '13.6 gal'\n",
      " '20.4 gal' '15 gal' '17.2 gal' '23.8 gal' '30 gal' '21.5 gal' '27.6 gal'\n",
      " '19.8 gal' '25.1 gal' '20.3 gal' '16.3 gal' '24.5 gal' '16.1 gal'\n",
      " '33.5 gal' '17.7 gal' '21.8 gal' '21.4 gal' '19.1 gal' '10.5 gal'\n",
      " '40 gal' '25 gal' '11.1 gal' '18.4 gal' '9.3 gal' '22.2 gal' '27.7 gal'\n",
      " '29 gal' '11.3 gal' '20.5 gal' '8.7 gal' '9.2 gal' '63.5 gal' '17.8 gal'\n",
      " '16.8 gal' '27 gal' '11.8 gal' '25.4 gal' '9.5 gal' '11 gal' '38 gal'\n",
      " '11.6 gal' '52 gal' '23.5 gal' '12.1 gal' '22.7 gal' '12 gal' '1.9 gal'\n",
      " '7.7 gal' '2.3 gal' '17.6 gal' '12.6 gal' '10 gal' '33 gal' '30.5 gal'\n",
      " '15.2 gal' '27.3 gal' '21.6 gal' '39 gal' '24.3 gal' '20.2 gal'\n",
      " '31.5 gal' '44 gal' '23.2 gal']\n",
      "['6 seats' '5 seats' '7 seats' nan '4 seats' '8 seats' '2 seats' '3 seats'\n",
      " '9 seats' '15 seats' '10 seats' '12 seats' '--']\n"
     ]
    }
   ],
   "source": [
    "#profiling class types:\n",
    "for col in ['engine_cylinders', 'engine_type','fuel_tank_volume','maximum_seating']:\n",
    "        print(df_cln_1[col].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After doing a quick profiling on some our identified columsn, we can see that both engine_cylinders and engine_type are the same. Additionally, we also found that the prefixes and suffixes attached to them are descriptive of it and thus not a continuous value. \n",
    "\n",
    "Regarding fuel_tank_volume and maximum_seating, we can see that there appears to be a pattern in the suffixes, \"gal\" and \"seats\" accordingly. We will now remove them and then convert all values to numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#removing unecesary string values in columns\n",
    "#then cleaning up any values that contain '--' and replacing it with NaN\n",
    "#Lastly, converting the value first to a string type and then to a float type\n",
    "\n",
    "df_cln_1['fuel_tank_volume']=df_cln_1['fuel_tank_volume'].str.replace(' gal', '').replace('--',np.NaN).astype(str).astype(float)\n",
    "df_cln_1['maximum_seating']=df_cln_1['maximum_seating'].str.replace(' seats', '').replace('--',np.NaN).astype(str).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before date fix: 0    2020-08-15\n",
      "1    2020-02-14\n",
      "Name: listed_date, dtype: object\n",
      "datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "#fixing date type values from object type to date time\n",
    "print(\"before date fix: \"+str(df_cln_1['listed_date'].head(2)))\n",
    "\n",
    "df_cln_1['listed_date']=pd.to_datetime(df_cln_1['listed_date'])\n",
    "print(df_cln_1['listed_date'].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "body_type                       object\n",
      "cabin                           object\n",
      "city                            object\n",
      "daysonmarket                     int64\n",
      "engine_cylinders                object\n",
      "engine_displacement            float64\n",
      "engine_type                     object\n",
      "fuel_tank_volume               float64\n",
      "fuel_type                       object\n",
      "highway_fuel_economy           float64\n",
      "listed_date             datetime64[ns]\n",
      "make_name                       object\n",
      "maximum_seating                float64\n",
      "mileage                        float64\n",
      "model_name                      object\n",
      "owner_count                    float64\n",
      "power                           object\n",
      "price                          float64\n",
      "torque                          object\n",
      "transmission                    object\n",
      "year                             int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#doing a quick profile on the subsetted columns\n",
    "print(df_cln_1.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now see that all of our column values have been adjusted to the correct datatypes. We will next proceed with cleaning up the values of our data. Since pandas default all 'object' types as strings, we will not need to convert these attribute types and can leave them as is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Cleaning - Data Values & NULLs\n",
    "Obviously at this point we need to convert a few of our data columns to the appropriate data type by removing parts of the value string that we do not need such as \"gal\" in the ful_tank_volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# finding all columns that have null values\n",
    "for i in df_cln_1.columns:\n",
    "    df_cln_1[i].isnull().any()\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
